{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65ce72-c724-4a11-9f88-50eb673e52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import keras\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import time\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Process\n",
    "from hailo_platform import (HEF, VDevice, HailoStreamInterface, InferVStreams, ConfigureParams,\n",
    "    InputVStreamParams, OutputVStreamParams, InputVStreams, OutputVStreams, FormatType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4c6b6-8af6-4b55-bf4c-5493ed1548d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowLength = 255\n",
    "fftLength = 255\n",
    "hop_length = 63 \n",
    "frame_length = 8064\n",
    "chunk = 8064\n",
    "rate = 48000\n",
    "\n",
    "#noisy_file = 'test_audio2.wav'\n",
    "noisy_file = 'noisy1.wav'\n",
    "clean_file = 'teset_cleanaudio.wav'\n",
    "MODEL_NAME = \"VOX_MODEL\"  # Replace with your model name\n",
    "HEF_FILE = 'New_FFT_Vox_Model.hef'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10668fc3-ab54-4121-a718-d638a375fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time_domain(predicted_clean,data_stft_phase,data_stft_mag):\n",
    "    predicted_clean = np.squeeze(predicted_clean)\n",
    "    print(\"This is the unsequeezes shaoe\")\n",
    "    print(predicted_clean.shape)\n",
    "  \n",
    "    predicted_mag_db_unscaled = (predicted_clean*80)-80\n",
    "    predicted_mag = librosa.db_to_amplitude(predicted_mag_db_unscaled, ref=np.max(data_stft_mag))\n",
    "    # predicted_sub = data_stft_mag - predicted_mag \n",
    "    predicted_stft = predicted_mag * data_stft_phase\n",
    "    predicted_final = librosa.istft(predicted_stft ,hop_length=hop_length, length=frame_length)\n",
    "\n",
    "    return(predicted_final)\n",
    "\n",
    "def convert_to_stft(data):\n",
    "    # data_stft = librosa.stft(data, n_fft=fftLength, win_length=windowLength, hop_length=overlap, window=window, center=True)\n",
    "    data_stft = librosa.stft(data, n_fft=fftLength, hop_length=hop_length)\n",
    "    data_stft_mag, data_stft_phase =librosa.magphase(data_stft)\n",
    "\n",
    "    data_stft_mag_db = librosa.amplitude_to_db(data_stft_mag, ref=np.max)\n",
    "    \n",
    "    data_stft_mag_db_scaled = (data_stft_mag_db+80)/80\n",
    "    print(\"this is the reka shape\")\n",
    "    print(data_stft_mag_db_scaled.shape)\n",
    "    data_stft_mag_db_scaled = np.reshape(data_stft_mag_db_scaled,(1,data_stft_mag_db_scaled.shape[0],data_stft_mag_db_scaled.shape[1],1))\n",
    "    return data_stft_mag_db_scaled,data_stft_mag,data_stft_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f1adf-d98b-45ef-9ace-155f5c230dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk Audio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # MODEL INPUT and OUTPUT\n",
    "    target = VDevice()\n",
    "    hef = HEF(HEF_FILE)\n",
    "\n",
    "   \n",
    "    #print(f\"Output Data Type: {output_info.dtype}\")\n",
    "    # Configure network groups\n",
    "    configure_params = ConfigureParams.create_from_hef(hef=hef, interface=HailoStreamInterface.PCIe)\n",
    "    network_groups = target.configure(hef, configure_params)\n",
    "    network_group = network_groups[0]\n",
    "    network_group_params = network_group.create_params()\n",
    "\n",
    "    input_vstreams_params = InputVStreamParams.make(network_group, format_type=FormatType.FLOAT32)\n",
    "    output_vstreams_params = OutputVStreamParams.make(network_group, format_type=FormatType.FLOAT32)\n",
    "\n",
    "    input_vstreams_info = hef.get_input_vstream_infos()[0]\n",
    "    output_vstreams_info = hef.get_output_vstream_infos()[0]\n",
    "     ##============================================================\n",
    "    \n",
    "    noisy_chunks = []\n",
    "    clean_audio_array = []\n",
    "    \n",
    "    noisy_sample, noisy_sample_rate = librosa.load(noisy_file)\n",
    "    print(noisy_sample.shape)\n",
    "    for j in range(chunk, len(noisy_sample), chunk):\n",
    "        k = j - chunk\n",
    "        noisy_chunks.append(noisy_sample[k:j])\n",
    "    #print(noisy_chunks)    \n",
    "    noisy_chunks = np.array(noisy_chunks)\n",
    "    #print(noisy_chunks)\n",
    "    print(noisy_chunks[0].shape)\n",
    "    \n",
    "    #for i in range(len(noisy_chunks):\n",
    "    for i in range(len(noisy_chunks)): \n",
    "        data_stft = librosa.stft(noisy_chunks[i], n_fft=fftLength, hop_length=hop_length)\n",
    "        chunk_stft_mag, chunkstft_phase =librosa.magphase(data_stft)\n",
    "        data_stft_mag_db = librosa.amplitude_to_db(chunk_stft_mag, ref=np.max)\n",
    "        chunk_stft_mag_db_scaled = (data_stft_mag_db+80)/80\n",
    "        print(\"this is the reka shape\")\n",
    "        print(chunk_stft_mag_db_scaled.shape)\n",
    "        chunk_stft_mag_db_scaled = np.reshape(chunk_stft_mag_db_scaled,(1,chunk_stft_mag_db_scaled.shape[0],chunk_stft_mag_db_scaled.shape[1],1))\n",
    "        data_stft_mag_db = np.reshape(data_stft_mag_db,(1,data_stft_mag_db.shape[0],data_stft_mag_db.shape[1],1))\n",
    "\n",
    "        print(chunk_stft_mag_db_scaled.shape)\n",
    "        \n",
    "        \n",
    "        #chunk_stft_mag_db_scaled, chunk_stft_mag, chunkstft_phase = convert_to_stft(noisy_chunks[i])\n",
    "        print(chunk_stft_mag_db_scaled.shape)\n",
    "        with InferVStreams(network_group,input_vstreams_params, output_vstreams_params) as infer_pipeline:\n",
    "            input_data = {input_vstreams_info.name: data_stft_mag_db }\n",
    "            with network_group.activate(network_group_params):\n",
    "                    infer_results = infer_pipeline.infer(input_data)\n",
    "                    #print('Stream output shape is {}'.format(infer_results[output_vstreams_info.name].shape))\n",
    "        result_arr = infer_results.get('New_FFT_Vox_Model/ne_activation_conv24')\n",
    "        print(\"this is the finla output shape\")\n",
    "        print(result_arr.shape)\n",
    "\n",
    "        predicted_clean = np.squeeze(result_arr)\n",
    "        print(\"This is the unsequeezes shape\")\n",
    "        print(predicted_clean.shape)\n",
    "  \n",
    "        predicted_mag_db_unscaled = (predicted_clean*80)-80\n",
    "        librosa.display.specshow(\n",
    "                predicted_mag_db_unscaled, \n",
    "                sr=rate, hop_length=hop_length, x_axis='time', y_axis='log',\n",
    "                vmin=-80, vmax=0\n",
    "                )\n",
    "        plt.colorbar(format=\"%+2.0f dB\")\n",
    "        plt.show()\n",
    "        predicted_mag = librosa.db_to_amplitude(predicted_mag_db_unscaled, ref=np.max(chunk_stft_mag))\n",
    "        # predicted_sub = data_stft_mag - predicted_mag \n",
    "        predicted_stft = predicted_mag * chunkstft_phase\n",
    "        clean_audio = librosa.istft(predicted_stft ,hop_length=hop_length, length=frame_length)\n",
    "    \n",
    "        #clean_audio = convert_to_time_domain(result_arr, chunkstft_phase, chunk_stft_mag)\n",
    "        print(\"clean audio shape\")\n",
    "        print(clean_audio.shape)\n",
    "        #print(chunkstft_phase.shape)\n",
    "        #print(chunk_stft_mag.shape)\n",
    "        clean_audio_array.append(clean_audio)\n",
    "    #chunk_stft = librosa.stft(noisy_chunks[0], n_fft = fftLength, hop_length = hop_length)\n",
    "    #chunk_stft_mag, chunkstft_phase = librosa.magphase(chunk_stft)\n",
    "    #chunk_stft_mag_db = librosa.amplitude_to_db(chunk_stft_mag, ref = np.max)\n",
    "    #chunk_stft_mag_db_scaled = (chunk_stft_mag_db + 80)/80\n",
    "    #chunk_stft_mag_db_scaled = np.reshape(chunk_stft_mag_db_scaled, (1,chunk_stft_mag_db_scaled.shape[0], chunk_stft_mag_db_scaled.shape[1],1))\n",
    "    #print(chunk_stft.shape)\n",
    "    #print(chunk_stft_mag_db)\n",
    "    #print(chunk_stft_mag_db_scaled)\n",
    "    print(chunk_stft_mag_db_scaled.shape)\n",
    "\n",
    "\n",
    "    #debug_wav_preprocessing(WAV_FILE)\n",
    "\n",
    "   # streaming_inference_from_wav()\n",
    "    #print(input_vstreams_info)\n",
    "    #print(output_vstreams_info)\n",
    "    \n",
    "    #with InferVStreams(network_group,input_vstreams_params, output_vstreams_params) as infer_pipeline:\n",
    "           # input_data = {input_vstreams_info.name: chunk_stft_mag_db_scaled}\n",
    "           # with network_group.activate(network_group_params):\n",
    "                  #  infer_results = infer_pipeline.infer(input_data)\n",
    "                  #  print('Stream output shape is {}'.format(infer_results[output_vstreams_info.name].shape))\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
